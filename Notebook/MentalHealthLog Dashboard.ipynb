{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e976c9-1457-4243-9e62-9727dbb24ed7",
   "metadata": {},
   "source": [
    "**Author:** Lu√≠s Sousa \n",
    "\n",
    "**Contact:** luis.95.sousa.31@gmail.com\n",
    "\n",
    "**Update log:**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created by Lu√≠s Sousa. Feel free to reach out for any questions or collaborations.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f14a8a-69bc-48ad-a346-a52ef0114da8",
   "metadata": {},
   "source": [
    "# Fetch data from email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439bbf6-4f2e-48fa-9d4f-90ec7d4fd3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Mock credentials (Replace with your own in a secure .env file or config)\n",
    "EMAIL = \"your_email@example.com\"\n",
    "PASSWORD = \"your_password\"\n",
    "IMAP_SERVER = \"imap.example.com\"\n",
    "\n",
    "# Search criteria\n",
    "SEARCH_SUBJECT = \"Mental Health Log\"\n",
    "DOWNLOAD_FOLDER = './downloads'  # Folder where attachments will be saved\n",
    "\n",
    "os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    filename = os.path.basename(filename)\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", filename)\n",
    "\n",
    "def connect_to_mail():\n",
    "    mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n",
    "    mail.login(EMAIL, PASSWORD)\n",
    "    return mail\n",
    "\n",
    "def search_emails(mail, subject):\n",
    "    mail.select(\"inbox\")\n",
    "    result, data = mail.search(None, f'(SUBJECT \"{subject}\")')\n",
    "    if result == \"OK\":\n",
    "        return data[0].split()\n",
    "    return []\n",
    "\n",
    "def download_attachments(mail, email_id):\n",
    "    result, msg_data = mail.fetch(email_id, \"(RFC822)\")\n",
    "    if result != \"OK\":\n",
    "        print(f\"Failed to fetch email {email_id.decode() if isinstance(email_id, bytes) else email_id}\")\n",
    "        return\n",
    "\n",
    "    for response_part in msg_data:\n",
    "        if isinstance(response_part, tuple):\n",
    "            msg = email.message_from_bytes(response_part[1])\n",
    "            subject, encoding = decode_header(msg.get(\"Subject\"))[0]\n",
    "            if isinstance(subject, bytes):\n",
    "                subject = subject.decode(encoding if encoding else \"utf-8\")\n",
    "            print(f\"Processing email: {subject}\")\n",
    "\n",
    "            for part in msg.walk():\n",
    "                if part.get_content_maintype() == \"multipart\":\n",
    "                    continue\n",
    "                if part.get(\"Content-Disposition\") is None:\n",
    "                    continue\n",
    "\n",
    "                filename = part.get_filename()\n",
    "                if filename:\n",
    "                    filename = decode_header(filename)[0][0]\n",
    "                    if isinstance(filename, bytes):\n",
    "                        filename = filename.decode()\n",
    "                    filename = sanitize_filename(filename)\n",
    "                    filepath = os.path.join(DOWNLOAD_FOLDER, filename)\n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        f.write(part.get_payload(decode=True))\n",
    "                    print(f\"Downloaded: {filename}\")\n",
    "\n",
    "def main():\n",
    "    mail = connect_to_mail()\n",
    "    print(\"Searching for emails with subject containing:\", SEARCH_SUBJECT)\n",
    "    email_ids = search_emails(mail, SEARCH_SUBJECT)\n",
    "    if not email_ids:\n",
    "        print(\"No emails found with the specified subject.\")\n",
    "    else:\n",
    "        print(f\"Found {len(email_ids)} emails. Downloading attachments...\")\n",
    "        for email_id in email_ids:\n",
    "            download_attachments(mail, email_id)\n",
    "    mail.logout()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da2564-4837-4b6f-a9e7-b6ebab7b656f",
   "metadata": {},
   "source": [
    "# Compile data in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118ef96-23b1-4798-a051-4c27058ce009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, List\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration (mocked for public use)\n",
    "FOLDER_PATH = \"./sample_data\"  # Replace with your actual path\n",
    "OUTPUT_FILE = \"./compiled/final_data.xlsx\"\n",
    "DATETIME_COLUMN = \"DateTime\"\n",
    "\n",
    "def fix_datetime_format(dt: Optional[str]) -> Optional[str]:\n",
    "    if not isinstance(dt, str) or dt.strip() == \"\":\n",
    "        return None\n",
    "    dt = dt.strip()\n",
    "    try:\n",
    "        date_part, time_part = dt.split(\" \")\n",
    "    except ValueError:\n",
    "        return None\n",
    "    patterns = [\n",
    "        (r\"\\b(\\d{1})/(\\d{1})/(\\d{2})\\b\", r\"0\\1/0\\2/20\\3\"),\n",
    "        (r\"\\b(\\d{1})/(\\d{2})/(\\d{2})\\b\", r\"0\\1/\\2/20\\3\"),\n",
    "        (r\"\\b(\\d{2})/(\\d{1})/(\\d{2})\\b\", r\"\\1/0\\2/20\\3\"),\n",
    "        (r\"\\b(\\d{2})/(\\d{2})/(\\d{2})\\b\", r\"\\1/\\2/20\\3\")\n",
    "    ]\n",
    "    for pattern, replacement in patterns:\n",
    "        date_part = re.sub(pattern, replacement, date_part)\n",
    "    time_parts = time_part.split(\":\")\n",
    "    if len(time_parts) == 2:\n",
    "        time_part = f\"{time_parts[0]}:{time_parts[1]}:00\"\n",
    "    elif len(time_parts) != 3:\n",
    "        return None\n",
    "    return f\"{date_part} {time_part}\"\n",
    "\n",
    "def standardize_datetime_column(df: pd.DataFrame, datetime_column: str) -> pd.DataFrame:\n",
    "    if datetime_column in df.columns:\n",
    "        df = df.copy()\n",
    "        df[datetime_column] = df[datetime_column].astype(str).str.strip()\n",
    "        df[datetime_column] = df[datetime_column].apply(fix_datetime_format)\n",
    "        df[datetime_column] = pd.to_datetime(\n",
    "            df[datetime_column],\n",
    "            format=\"%d/%m/%Y %H:%M:%S\",\n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "        failed_rows = df[datetime_column].isna().sum()\n",
    "        if failed_rows > 0:\n",
    "            print(f\"‚ö†Ô∏è Warning: {failed_rows} rows had invalid DateTime format\")\n",
    "    return df\n",
    "\n",
    "def read_and_compile_csvs(folder_path: str, datetime_column: str, output_file: Optional[str] = None) -> Optional[pd.DataFrame]:\n",
    "    folder_path = Path(folder_path)\n",
    "    if not folder_path.exists():\n",
    "        print(f\"‚ùå Folder '{folder_path}' does not exist\")\n",
    "        return None\n",
    "    csv_files = list(folder_path.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(\"‚ùå No CSV files found in the folder\")\n",
    "        return None\n",
    "    dataframes: List[pd.DataFrame] = []\n",
    "    total_rows = 0\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "            if datetime_column in df.columns:\n",
    "                print(f\"üìÇ Processing {file.name} ({len(df)} rows)\")\n",
    "                df = standardize_datetime_column(df, datetime_column)\n",
    "                dataframes.append(df)\n",
    "                total_rows += len(df)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Skipping {file.name} - No '{datetime_column}' column found\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading {file.name}: {str(e)}\")\n",
    "    if not dataframes:\n",
    "        print(\"‚ùå No valid CSV files were processed\")\n",
    "        return None\n",
    "    print(f\"üîÑ Combining {len(dataframes)} files ({total_rows} total rows)...\")\n",
    "    compiled_df = pd.concat(dataframes, ignore_index=True)\n",
    "    initial_rows = len(compiled_df)\n",
    "    compiled_df = compiled_df.dropna(subset=[datetime_column])\n",
    "    compiled_df = compiled_df.sort_values(by=datetime_column)\n",
    "    rows_dropped = initial_rows - len(compiled_df)\n",
    "    if rows_dropped > 0:\n",
    "        print(f\"‚ö†Ô∏è Dropped {rows_dropped} rows with invalid DateTime values\")\n",
    "    if output_file:\n",
    "        output_path = Path(output_file)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        compiled_df[datetime_column] = compiled_df[datetime_column].dt.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "            compiled_df.to_excel(writer, index=False, sheet_name='Data')\n",
    "        print(f\"‚úÖ Saved {len(compiled_df)} rows to '{output_path}'\")\n",
    "    return compiled_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_df = read_and_compile_csvs(FOLDER_PATH, DATETIME_COLUMN, OUTPUT_FILE)\n",
    "    if result_df is not None:\n",
    "        print(f\"üìä Final DataFrame Statistics:\")\n",
    "        print(f\"Total rows: {len(result_df):,}\")\n",
    "        print(f\"Date range: {result_df[DATETIME_COLUMN].min()} to {result_df[DATETIME_COLUMN].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166aad5b-6ed9-461f-9025-69e82c2bde3b",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39fada2-c202-4d8b-a732-7ccd6204e5bd",
   "metadata": {},
   "source": [
    "## General overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02737e8-e164-41fa-a184-4c9811a3c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Load the sample data\n",
    "df = pd.read_excel('./compiled/final_data.xlsx') \n",
    "\n",
    "# Convert DateTime column\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Define ordered feelings\n",
    "feeling_order = [\n",
    "    'Very Unpleasant', 'Unpleasant', 'Slightly Unpleasant',\n",
    "    'Neutral', 'Pleasant', 'Very Pleasant'\n",
    "]\n",
    "\n",
    "df['Feeling'] = pd.Categorical(df['Feeling'], categories=feeling_order, ordered=True)\n",
    "\n",
    "# Emotion palette\n",
    "emotion_colors = {\n",
    "    'Joy': '#2196F3',\n",
    "    'Love': '#FF69B4',\n",
    "    'Calm': '#90CAF9',\n",
    "    'Hope': '#AED581',\n",
    "    'Contentment': '#4CAF50',\n",
    "    'Surprise': '#FFD54F',\n",
    "    'Nostalgia': '#CE93D8',\n",
    "    'Sadness': '#9C27B0',\n",
    "    'Anger': '#F44336',\n",
    "    'Fear': '#7B1FA2',\n",
    "    'Drained': '#B0BEC5',\n",
    "    'Anxiety': '#FFC107',\n",
    "    'Frustration': '#FF7043'\n",
    "}\n",
    "\n",
    "feeling_colors = {\n",
    "    'Very Unpleasant': '#d32f2f',\n",
    "    'Unpleasant': '#f44336',\n",
    "    'Slightly Unpleasant': '#ff7043',\n",
    "    'Neutral': '#ffca28',\n",
    "    'Pleasant': '#81c784',\n",
    "    'Very Pleasant': '#2e7d32'\n",
    "}\n",
    "\n",
    "# Emotion Distribution Pie Chart\n",
    "fig_emotion = px.pie(\n",
    "    values=df['Emotion'].value_counts().values,\n",
    "    names=df['Emotion'].value_counts().index,\n",
    "    title='Emotion Distribution',\n",
    "    color=df['Emotion'].value_counts().index,\n",
    "    color_discrete_map=emotion_colors\n",
    ")\n",
    "fig_emotion.show()\n",
    "\n",
    "# Feeling Distribution Pie Chart\n",
    "feeling_counts = df['Feeling'].value_counts().reindex(feeling_order)\n",
    "fig_feeling = go.Figure(data=[go.Pie(\n",
    "    labels=feeling_counts.index,\n",
    "    values=feeling_counts.values,\n",
    "    marker_colors=[feeling_colors.get(feeling, \"#ccc\") for feeling in feeling_order],\n",
    "    hovertemplate=\"<b>%{label}</b><br>Count: %{value}<extra></extra>\",\n",
    "    direction='clockwise',\n",
    "    sort=False\n",
    ")])\n",
    "fig_feeling.update_layout(title='Feeling Distribution')\n",
    "fig_feeling.show()\n",
    "\n",
    "# Mood Timeline\n",
    "fig_timeline = go.Figure()\n",
    "fig_timeline.add_trace(go.Scatter(\n",
    "    x=df['DateTime'],\n",
    "    y=df['Feeling'],\n",
    "    name='Feeling',\n",
    "    mode='lines+markers',\n",
    "    line={'color': '#2196F3'},\n",
    "    marker={'color': [feeling_colors.get(f, '#ccc') for f in df['Feeling']]}\n",
    "))\n",
    "fig_timeline.update_layout(\n",
    "    title='Mood Timeline',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Feeling',\n",
    "    hovermode='x unified',\n",
    "    yaxis={'categoryorder': 'array', 'categoryarray': feeling_order}\n",
    ")\n",
    "fig_timeline.show()\n",
    "\n",
    "# Habits Overview\n",
    "fig_habits = make_subplots(rows=1, cols=2, subplot_titles=('Exercise', 'Meditation'))\n",
    "habit_colors = {'yes': '#f44336', 'no': '#4CAF50'}\n",
    "\n",
    "exercise_counts = df['Exercise'].value_counts()\n",
    "alcohol_counts = df['Meditation'].value_counts()\n",
    "\n",
    "fig_habits.add_trace(go.Bar(\n",
    "    x=['Yes', 'No'],\n",
    "    y=[exercise_counts.get('yes', 0), exercise_counts.get('no', 0)],\n",
    "    marker_color=[habit_colors['yes'], habit_colors['no']]\n",
    "), row=1, col=1)\n",
    "\n",
    "fig_habits.add_trace(go.Bar(\n",
    "    x=['Yes', 'No'],\n",
    "    y=[alcohol_counts.get('yes', 0), alcohol_counts.get('no', 0)],\n",
    "    marker_color=[habit_colors['yes'], habit_colors['no']]\n",
    "), row=1, col=2)\n",
    "\n",
    "fig_habits.update_layout(title='Habits Overview', showlegend=False)\n",
    "fig_habits.show()\n",
    "\n",
    "# Current Mood Summary\n",
    "latest = df.iloc[-1]\n",
    "print(\"\\nCurrent Mood:\")\n",
    "print(f\"Feeling: {latest['Feeling']}\")\n",
    "print(f\"Emotion: {latest['Emotion']}\")\n",
    "print(f\"Thoughts: {latest['Thoughts']}\")\n",
    "\n",
    "# Recent Entries\n",
    "print(\"\\nRecent Entries:\")\n",
    "print(df.tail(5)[['DateTime', 'Feeling', 'Emotion', 'Thoughts']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12f9cf-917e-4d30-b9db-21d6030cf8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Read and prepare data\n",
    "df = pd.read_excel('./compiled/final_data.xlsx') \n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Add derived time features\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "df['DayOfWeek'] = df['DateTime'].dt.day_name()\n",
    "df['Date'] = df['DateTime'].dt.date\n",
    "\n",
    "# Define feeling order and colors\n",
    "feeling_order = [\n",
    "    'Very Unpleasant',\n",
    "    'Unpleasant',\n",
    "    'Slightly Unpleasant',\n",
    "    'Neutral',\n",
    "    'Pleasant',\n",
    "    'Very Pleasant'\n",
    "]\n",
    "\n",
    "feeling_colors = {\n",
    "    'Very Unpleasant': '#d32f2f',\n",
    "    'Unpleasant': '#f44336',\n",
    "    'Slightly Unpleasant': '#ff7043',\n",
    "    'Neutral': '#ffca28',\n",
    "    'Pleasant': '#81c784',\n",
    "    'Very Pleasant': '#2e7d32'\n",
    "}\n",
    "\n",
    "# 1. Create Time-of-Day Mood Pattern Analysis\n",
    "def create_hourly_mood_heatmap():\n",
    "    hourly_mood = pd.crosstab(df['Hour'], df['Feeling'])\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=hourly_mood.values,\n",
    "        x=hourly_mood.columns,\n",
    "        y=hourly_mood.index,\n",
    "        colorscale=[\n",
    "            [0, '#d32f2f'],\n",
    "            [0.2, '#f44336'],\n",
    "            [0.4, '#ff7043'],\n",
    "            [0.6, '#ffca28'],\n",
    "            [0.8, '#81c784'],\n",
    "            [1, '#2e7d32']\n",
    "        ],\n",
    "        hoverongaps=False,\n",
    "        hovertemplate='Hour: %{y}<br>Feeling: %{x}<br>Count: %{z}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Mood Patterns by Hour of Day',\n",
    "        xaxis_title='Feeling',\n",
    "        yaxis_title='Hour of Day',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 2. Create corrected Emotion-Habit Sankey\n",
    "def create_emotion_habit_sankey():\n",
    "    emotion_exercise = df.groupby(['Emotion', 'Exercise']).size().reset_index(name='count')\n",
    "    emotion_meditation = df.groupby(['Emotion', 'Meditation']).size().reset_index(name='count')\n",
    "    \n",
    "    emotions = df['Emotion'].unique()\n",
    "    habits = ['Exercise - Yes', 'Exercise - No', 'Meditation - Yes', 'Meditation - No']\n",
    "    \n",
    "    labels = list(emotions) + habits\n",
    "    emotion_to_idx = {emotion: idx for idx, emotion in enumerate(emotions)}\n",
    "    \n",
    "    source = []\n",
    "    target = []\n",
    "    value = []\n",
    "    \n",
    "    for _, row in emotion_exercise.iterrows():\n",
    "        if row['count'] > 0:\n",
    "            source.append(emotion_to_idx[row['Emotion']])\n",
    "            target.append(len(emotions) + (0 if row['Exercise'] == 'yes' else 1))\n",
    "            value.append(row['count'])\n",
    "    \n",
    "    for _, row in emotion_meditation.iterrows():\n",
    "        if row['count'] > 0:\n",
    "            source.append(emotion_to_idx[row['Emotion']])\n",
    "            target.append(len(emotions) + (2 if row['Meditation'] == 'yes' else 3))\n",
    "            value.append(row['count'])\n",
    "    \n",
    "    emotion_colors = {\n",
    "            'Joy': '#2196F3',\n",
    "            'Love': '#FF69B4',\n",
    "            'Calm': '#90CAF9',\n",
    "            'Hope': '#AED581',\n",
    "            'Contentment': '#4CAF50',\n",
    "            'Surprise': '#FFD54F',\n",
    "            'Nostalgia': '#CE93D8',\n",
    "            'Sadness': '#9C27B0',\n",
    "            'Anger': '#F44336',\n",
    "            'Fear': '#7B1FA2',\n",
    "            'Drained': '#B0BEC5',\n",
    "            'Anxiety': '#FFC107',\n",
    "            'Frustration': '#FF7043'\n",
    "    }\n",
    "    \n",
    "    node_colors = [emotion_colors.get(label, '#ff7043') if label in emotions \n",
    "                  else '#ff7043' if 'Yes' in label \n",
    "                  else '#81c784' for label in labels]\n",
    "    \n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=labels,\n",
    "            color=node_colors\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=source,\n",
    "            target=target,\n",
    "            value=value\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Emotion-Exercise and Meditation Relationships',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 4. Create Contributing Factors Analysis\n",
    "def create_factors_analysis():\n",
    "    df['Factors'] = df['Contributing Factors'].str.split(',')\n",
    "    factors = [factor.strip() for factors in df['Factors'].dropna() for factor in factors]\n",
    "    factor_counts = pd.Series(factors).value_counts()\n",
    "    \n",
    "    fig = go.Figure(go.Sunburst(\n",
    "        labels=factor_counts.index,\n",
    "        parents=[''] * len(factor_counts),\n",
    "        values=factor_counts.values,\n",
    "        branchvalues='total'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Contributing Factors Analysis',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display all visualizations\n",
    "print(\"Generating visualizations...\\n\")\n",
    "\n",
    "hourly_heatmap = create_hourly_mood_heatmap()\n",
    "emotion_habit_sankey = create_emotion_habit_sankey()\n",
    "factors_analysis = create_factors_analysis()\n",
    "\n",
    "hourly_heatmap.show()\n",
    "emotion_habit_sankey.show()\n",
    "factors_analysis.show()\n",
    "\n",
    "# Calculate and display insights\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Mood volatility\n",
    "mood_scores = {\n",
    "    'Very Unpleasant': 0,\n",
    "    'Unpleasant': 1,\n",
    "    'Slightly Unpleasant': 2,\n",
    "    'Neutral': 3,\n",
    "    'Pleasant': 4,\n",
    "    'Very Pleasant': 5\n",
    "}\n",
    "df['MoodScore'] = df['Feeling'].map(mood_scores)\n",
    "mood_volatility = df.groupby('Date')['MoodScore'].std().mean()\n",
    "print(f\"Average daily mood volatility: {mood_volatility:.2f}\")\n",
    "\n",
    "# Activity correlations\n",
    "exercise_impact = df.groupby('Exercise')['MoodScore'].mean()\n",
    "meditation_impact = df.groupby('Meditation')['MoodScore'].mean()\n",
    "\n",
    "print(\"\\nAverage mood scores (0-5 scale):\")\n",
    "print(f\"When exercising: Yes = {exercise_impact.get('yes', 'N/A'):.2f}, No = {exercise_impact.get('no', 'N/A'):.2f}\")\n",
    "print(f\"When meditating: Yes = {meditation_impact.get('yes', 'N/A'):.2f}, No = {meditation_impact.get('no', 'N/A'):.2f}\")\n",
    "\n",
    "# Most common emotion-feeling pairs\n",
    "emotion_feeling_pairs = pd.crosstab(df['Emotion'], df['Feeling'])\n",
    "print(\"\\nEmotion-Feeling Combinations:\")\n",
    "print(emotion_feeling_pairs)\n",
    "\n",
    "# Time of day patterns\n",
    "print(\"\\nMood by Time of Day:\")\n",
    "hourly_mood_avg = df.groupby('Hour')['MoodScore'].mean().sort_values(ascending=False)\n",
    "best_hours = hourly_mood_avg.head(3)\n",
    "worst_hours = hourly_mood_avg.tail(3)\n",
    "\n",
    "print(\"\\nBest hours for mood:\")\n",
    "for hour, score in best_hours.items():\n",
    "    print(f\"{hour:02d}:00 - Score: {score:.2f}\")\n",
    "\n",
    "print(\"\\nWorst hours for mood:\")\n",
    "for hour, score in worst_hours.items():\n",
    "    print(f\"{hour:02d}:00 - Score: {score:.2f}\")\n",
    "\n",
    "# Emotion frequencies\n",
    "print(\"\\nEmotion Frequencies:\")\n",
    "print(df['Emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3311f1-54dd-4b64-a801-0945f2350099",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Day vs Night mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1724bb-32d3-4317-8182-00d8993a74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Read and prepare data\n",
    "df = pd.read_excel('./compiled/final_data.xlsx')\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M:%S')\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "\n",
    "# Create filter masks for day and night\n",
    "day_mask = (df['Hour'] >= 7) & (df['Hour'] < 19)\n",
    "night_mask = ~day_mask\n",
    "\n",
    "# Function to create Sankey diagram\n",
    "def create_emotion_activity_sankey(data, title):\n",
    "    emotion_exercise = data.groupby(['Emotion', 'Exercise']).size().reset_index(name='count')\n",
    "    emotion_meditation = data.groupby(['Emotion', 'Meditation']).size().reset_index(name='count')\n",
    "    \n",
    "    emotions = data['Emotion'].unique()\n",
    "    activities = ['Exercise - Yes', 'Exercise - No', 'Meditation - Yes', 'Meditation - No']\n",
    "    \n",
    "    labels = list(emotions) + activities\n",
    "    emotion_to_idx = {emotion: idx for idx, emotion in enumerate(emotions)}\n",
    "    \n",
    "    source = []\n",
    "    target = []\n",
    "    value = []\n",
    "    \n",
    "    for _, row in emotion_exercise.iterrows():\n",
    "        if row['count'] > 0:\n",
    "            source.append(emotion_to_idx[row['Emotion']])\n",
    "            target.append(len(emotions) + (0 if row['Exercise'] == 'yes' else 1))\n",
    "            value.append(row['count'])\n",
    "    \n",
    "    for _, row in emotion_meditation.iterrows():\n",
    "        if row['count'] > 0:\n",
    "            source.append(emotion_to_idx[row['Emotion']])\n",
    "            target.append(len(emotions) + (2 if row['Meditation'] == 'yes' else 3))\n",
    "            value.append(row['count'])\n",
    "    \n",
    "    emotion_colors = {\n",
    "            'Joy': '#2196F3',\n",
    "            'Love': '#FF69B4',\n",
    "            'Calm': '#90CAF9',\n",
    "            'Hope': '#AED581',\n",
    "            'Contentment': '#4CAF50',\n",
    "            'Surprise': '#FFD54F',\n",
    "            'Nostalgia': '#CE93D8',\n",
    "            'Sadness': '#9C27B0',\n",
    "            'Anger': '#F44336',\n",
    "            'Fear': '#7B1FA2',\n",
    "            'Drained': '#B0BEC5',\n",
    "            'Anxiety': '#FFC107',\n",
    "            'Frustration': '#FF7043'\n",
    "    }\n",
    "    \n",
    "    node_colors = [emotion_colors.get(label, '#ff7043') if label in emotions \n",
    "                  else '#ff7043' if 'Yes' in label \n",
    "                  else '#81c784' for label in labels]\n",
    "    \n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=labels,\n",
    "            color=node_colors\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=source,\n",
    "            target=target,\n",
    "            value=value\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        font_size=12,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create daytime Sankey\n",
    "day_df = df[day_mask]\n",
    "day_sankey = create_emotion_activity_sankey(\n",
    "    day_df, \n",
    "    'Daytime Emotion-Activity Relationships (7 AM - 7 PM)'\n",
    ")\n",
    "day_sankey.show()\n",
    "\n",
    "# Create nighttime Sankey\n",
    "night_df = df[night_mask]\n",
    "night_sankey = create_emotion_activity_sankey(\n",
    "    night_df, \n",
    "    'Nighttime Emotion-Activity Relationships (7 PM - 7 AM)'\n",
    ")\n",
    "night_sankey.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nDaytime Summary (7 AM - 7 PM):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total entries: {len(day_df)}\")\n",
    "print(\"\\nEmotion frequencies:\")\n",
    "print(day_df['Emotion'].value_counts())\n",
    "print(\"\\nExercise frequency:\")\n",
    "print(day_df['Exercise'].value_counts())\n",
    "print(\"\\nMeditation frequency:\")\n",
    "print(day_df['Meditation'].value_counts())\n",
    "\n",
    "print(\"\\nNighttime Summary (7 PM - 7 AM):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total entries: {len(night_df)}\")\n",
    "print(\"\\nEmotion frequencies:\")\n",
    "print(night_df['Emotion'].value_counts())\n",
    "print(\"\\nExercise frequency:\")\n",
    "print(night_df['Exercise'].value_counts())\n",
    "print(\"\\nMeditation frequency:\")\n",
    "print(night_df['Meditation'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce330a-656f-4973-ae65-12e2cb58fe82",
   "metadata": {},
   "source": [
    "## Exercise patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd22e5-1059-4d7c-876b-06ed5955f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Read and prepare data\n",
    "df = pd.read_excel('./compiled/final_data.xlsx')\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M:%S')\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "\n",
    "# 1. Analyze exercise probability during different emotional states\n",
    "def analyze_emotion_exercise_relationship():\n",
    "    # Calculate exercise probability for each emotion\n",
    "    emotion_exercise = pd.crosstab(df['Emotion'], df['Exercise'], normalize='index')\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=emotion_exercise.index,\n",
    "        y=emotion_exercise['yes'] * 100,\n",
    "        name='Exercise Probability',\n",
    "        marker_color=['#ff7043' if x > emotion_exercise['yes'].mean() else '#81c784' \n",
    "                     for x in emotion_exercise['yes']]\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Probability of Exercise by Emotional State',\n",
    "        xaxis_title='Emotion',\n",
    "        yaxis_title='Exercise Probability (%)',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig, emotion_exercise\n",
    "\n",
    "# 2. Analyze timing patterns of exercise\n",
    "def analyze_exercise_timing():\n",
    "    # Calculate exercise probability by hour\n",
    "    hourly_exercise = pd.crosstab(df['Hour'], df['Exercise'], normalize='index')\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=hourly_exercise.index,\n",
    "        y=hourly_exercise['yes'] * 100,\n",
    "        mode='lines+markers',\n",
    "        name='Exercise Probability',\n",
    "        line=dict(color='#ff7043')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Exercise Probability Throughout the Day',\n",
    "        xaxis_title='Hour of Day',\n",
    "        yaxis_title='Exercise Probability (%)',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig, hourly_exercise\n",
    "\n",
    "# 3. Analyze contributing factors relation to exercise\n",
    "def analyze_contributing_factors():\n",
    "    # Split contributing factors and create pairs with exercise status\n",
    "    df['Factors'] = df['Contributing Factors'].str.split(',')\n",
    "    factor_exercise_pairs = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if isinstance(row['Factors'], list):\n",
    "            for factor in row['Factors']:\n",
    "                factor = factor.strip()\n",
    "                factor_exercise_pairs.append({\n",
    "                    'Factor': factor,\n",
    "                    'Exercise': row['Exercise']\n",
    "                })\n",
    "    \n",
    "    factor_df = pd.DataFrame(factor_exercise_pairs)\n",
    "    factor_exercise = pd.crosstab(factor_df['Factor'], factor_df['Exercise'], normalize='index')\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=factor_exercise.index,\n",
    "        y=factor_exercise['yes'] * 100,\n",
    "        name='Exercise Probability',\n",
    "        marker_color='#ff7043'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Exercise Probability by Contributing Factor',\n",
    "        xaxis_title='Contributing Factor',\n",
    "        yaxis_title='Exercise Probability (%)',\n",
    "        height=500,\n",
    "        xaxis_tickangle=-45\n",
    "    )\n",
    "    \n",
    "    return fig, factor_exercise\n",
    "\n",
    "# 4. Analyze feeling intensity and exercise\n",
    "def analyze_feeling_intensity():\n",
    "    # Create feeling intensity scale\n",
    "    feeling_intensity = {\n",
    "        'Very Pleasant': 2,\n",
    "        'Pleasant': 1,\n",
    "        'Neutral': 0,\n",
    "        'Slightly Unpleasant': -1,\n",
    "        'Unpleasant': -2,\n",
    "        'Very Unpleasant': -3\n",
    "    }\n",
    "    \n",
    "    df['Feeling_Intensity'] = df['Feeling'].map(feeling_intensity)\n",
    "    \n",
    "    # Calculate average feeling intensity for exercise vs non-exercise\n",
    "    exercise_intensity = df.groupby('Exercise')['Feeling_Intensity'].agg(['mean', 'std']).round(2)\n",
    "    \n",
    "    # Create box plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(\n",
    "        x=df[df['Exercise'] == 'yes']['Feeling_Intensity'],\n",
    "        name='Exercised',\n",
    "        marker_color='#ff7043'\n",
    "    ))\n",
    "    fig.add_trace(go.Box(\n",
    "        x=df[df['Exercise'] == 'no']['Feeling_Intensity'],\n",
    "        name='Did Not Exercise',\n",
    "        marker_color='#81c784'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Feeling Intensity Distribution: Exercise vs Non-Exercise',\n",
    "        xaxis_title='Feeling Intensity',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig, exercise_intensity\n",
    "\n",
    "# Generate all analyses\n",
    "emotion_fig, emotion_stats = analyze_emotion_exercise_relationship()\n",
    "timing_fig, timing_stats = analyze_exercise_timing()\n",
    "factors_fig, factors_stats = analyze_contributing_factors()\n",
    "intensity_fig, intensity_stats = analyze_feeling_intensity()\n",
    "\n",
    "# Display visualizations\n",
    "emotion_fig.show()\n",
    "timing_fig.show()\n",
    "factors_fig.show()\n",
    "intensity_fig.show()\n",
    "\n",
    "# Print statistical insights\n",
    "print(\"\\nActivity Analysis Results:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n1. Emotion-Based Exercise Probabilities:\")\n",
    "print(emotion_stats['yes'].sort_values(ascending=False) * 100)\n",
    "\n",
    "print(\"\\n2. Peak Exercise Hours:\")\n",
    "peak_hours = timing_stats['yes'].sort_values(ascending=False).head(3)\n",
    "print(peak_hours * 100)\n",
    "\n",
    "print(\"\\n3. Contributing Factors Impact on Exercise:\")\n",
    "print(factors_stats['yes'].sort_values(ascending=False) * 100)\n",
    "\n",
    "print(\"\\n4. Feeling Intensity Analysis:\")\n",
    "print(\"Average feeling intensity when exercising vs not exercising:\")\n",
    "print(intensity_stats)\n",
    "\n",
    "# Calculate conditional probabilities\n",
    "print(\"\\n5. Additional Insights:\")\n",
    "negative_emotions = ['Anxiety', 'Frustration', 'Anger', 'Sadness', 'Fear', 'Drained']\n",
    "positive_emotions = ['Joy', 'Contentment', 'Love', 'Calm', 'Hope', 'Surprise', 'Nostalgia']\n",
    "\n",
    "neg_exercise_prob = len(df[(df['Emotion'].isin(negative_emotions)) & (df['Exercise'] == 'yes')]) / len(df[df['Emotion'].isin(negative_emotions)])\n",
    "pos_exercise_prob = len(df[(df['Emotion'].isin(positive_emotions)) & (df['Exercise'] == 'yes')]) / len(df[df['Emotion'].isin(positive_emotions)])\n",
    "\n",
    "print(f\"\\nExercise probability during negative emotions: {neg_exercise_prob:.2%}\")\n",
    "print(f\"Exercise probability during positive emotions: {pos_exercise_prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0348e3-8dcf-468b-9186-92f4a046840e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
